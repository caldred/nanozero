{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Weight Power Ablation: Variance Aggregation in Bayesian MCTS\n",
        "\n",
        "This notebook tests different powers for the weight term in variance aggregation:\n",
        "\n",
        "```\n",
        "agg_sigma_sq = sum(w^p * (sigma_sq + disagreement))\n",
        "```\n",
        "\n",
        "Current implementation uses `p=2` (squared weights), but since weights are somewhat correlated, the optimal power may be between 1 and 2.\n",
        "\n",
        "**Hypothesis:** If weights are:\n",
        "- Perfectly independent: p=2 is optimal (sum of variances)\n",
        "- Perfectly correlated: p=1 is optimal (linear combination)\n",
        "- Partially correlated: Optimal p is between 1 and 2\n",
        "\n",
        "**Setup:** Use `Runtime > Change runtime type > GPU` for best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Rust toolchain\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "import os\n",
        "os.environ[\"PATH\"] = f\"{os.environ['HOME']}/.cargo/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "# Verify Rust installation\n",
        "!rustc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/caldred/nanozero.git\n",
        "%cd nanozero\n",
        "\n",
        "# Install Python dependencies\n",
        "!pip install -q numpy scipy maturin\n",
        "\n",
        "# Build and install Rust extension\n",
        "%cd nanozero-mcts-rs\n",
        "!maturin build --release\n",
        "!pip install target/wheels/nanozero_mcts_rs-*.whl\n",
        "%cd ..\n",
        "\n",
        "# Verify Rust backend is available\n",
        "!python -c \"from nanozero.game import RUST_AVAILABLE; print(f'Rust backend available: {RUST_AVAILABLE}')\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Train Connect4 Model\n",
        "\n",
        "First, train a model we'll use for all ablation tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Connect4 - A100 optimized settings\n",
        "# ~5-10 minutes on A100\n",
        "!python -m scripts.train \\\n",
        "    --game=connect4 \\\n",
        "    --n_layer=4 \\\n",
        "    --num_iterations=150 \\\n",
        "    --games_per_iteration=64 \\\n",
        "    --training_steps=200 \\\n",
        "    --mcts_simulations=100 \\\n",
        "    --batch_size=256 \\\n",
        "    --buffer_size=100000 \\\n",
        "    --parallel_games=128 \\\n",
        "    --eval_interval=25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Modified Bayesian MCTS with Configurable Weight Power\n",
        "\n",
        "Create a subclass that allows specifying the weight power `p` in variance aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from nanozero.config import BayesianMCTSConfig\n",
        "from nanozero.game import Game\n",
        "from nanozero.mcts import TranspositionTable\n",
        "\n",
        "\n",
        "def normal_cdf(x: float) -> float:\n",
        "    \"\"\"Standard normal CDF using error function.\"\"\"\n",
        "    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "class BayesianNodeWithPower:\n",
        "    \"\"\"\n",
        "    MCTS tree node with Gaussian belief over value.\n",
        "    Modified to support configurable weight power in variance aggregation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, prior: float = 0.0, mu: float = 0.0, sigma_sq: float = 1.0):\n",
        "        self.prior = prior\n",
        "        self.mu = mu\n",
        "        self.sigma_sq = sigma_sq\n",
        "        self.children: Dict[int, 'BayesianNodeWithPower'] = {}\n",
        "        self.agg_mu: Optional[float] = None\n",
        "        self.agg_sigma_sq: Optional[float] = None\n",
        "        self.visits: int = 0\n",
        "\n",
        "    def expanded(self) -> bool:\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def sample(self) -> float:\n",
        "        return np.random.normal(self.mu, math.sqrt(self.sigma_sq))\n",
        "\n",
        "    def update(self, value: float, obs_var: float, min_var: float = 1e-6) -> None:\n",
        "        precision_prior = 1.0 / max(self.sigma_sq, min_var)\n",
        "        precision_obs = 1.0 / max(obs_var, min_var)\n",
        "        new_precision = precision_prior + precision_obs\n",
        "        self.mu = (precision_prior * self.mu + precision_obs * value) / new_precision\n",
        "        self.sigma_sq = max(1.0 / new_precision, min_var)\n",
        "\n",
        "    def precision(self) -> float:\n",
        "        return 1.0 / self.sigma_sq\n",
        "\n",
        "    def aggregate_children(\n",
        "        self, \n",
        "        prune_threshold: float = 0.01, \n",
        "        visited_only: bool = False,\n",
        "        weight_power: float = 2.0  # NEW PARAMETER\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Compute aggregated belief from children using optimality weights.\n",
        "        \n",
        "        Args:\n",
        "            prune_threshold: Children with P(optimal) < threshold get weight 0\n",
        "            visited_only: If True, only aggregate children that have been visited\n",
        "            weight_power: Power to raise weights to in variance aggregation (1 to 2)\n",
        "        \"\"\"\n",
        "        if not self.children:\n",
        "            return\n",
        "\n",
        "        if visited_only:\n",
        "            children = [c for c in self.children.values() if c.visits > 0]\n",
        "            if not children:\n",
        "                return\n",
        "        else:\n",
        "            children = list(self.children.values())\n",
        "\n",
        "        n = len(children)\n",
        "\n",
        "        if n == 1:\n",
        "            child = children[0]\n",
        "            self.agg_mu = -child.mu\n",
        "            self.agg_sigma_sq = child.sigma_sq\n",
        "            return\n",
        "\n",
        "        # Get child beliefs from parent's perspective (negate child values)\n",
        "        mus = np.array([-c.mu for c in children])\n",
        "        sigma_sqs = np.array([c.sigma_sq for c in children])\n",
        "\n",
        "        # Find leader and challenger by mean\n",
        "        sorted_idx = np.argsort(mus)[::-1]\n",
        "        leader_idx = sorted_idx[0]\n",
        "        challenger_idx = sorted_idx[1]\n",
        "\n",
        "        # Compute optimality scores via pairwise Gaussian CDF comparisons\n",
        "        scores = np.zeros(n)\n",
        "        mu_L, sigma_sq_L = mus[leader_idx], sigma_sqs[leader_idx]\n",
        "        mu_C, sigma_sq_C = mus[challenger_idx], sigma_sqs[challenger_idx]\n",
        "\n",
        "        for i in range(n):\n",
        "            if i == leader_idx:\n",
        "                diff = mu_L - mu_C\n",
        "                std = math.sqrt(sigma_sq_L + sigma_sq_C)\n",
        "            else:\n",
        "                diff = mus[i] - mu_L\n",
        "                std = math.sqrt(sigma_sqs[i] + sigma_sq_L)\n",
        "\n",
        "            if std > 1e-10:\n",
        "                scores[i] = normal_cdf(diff / std)\n",
        "            else:\n",
        "                scores[i] = 1.0 if diff > 0 else 0.0\n",
        "\n",
        "        # Soft prune and normalize\n",
        "        scores[scores < prune_threshold] = 0.0\n",
        "        total = scores.sum()\n",
        "        if total < 1e-10:\n",
        "            weights = np.ones(n) / n\n",
        "        else:\n",
        "            weights = scores / total\n",
        "\n",
        "        # Aggregated mean (weighted average of children)\n",
        "        self.agg_mu = float(np.sum(weights * mus))\n",
        "\n",
        "        # Aggregated variance with CONFIGURABLE weight power\n",
        "        disagreement = (mus - self.agg_mu) ** 2\n",
        "        self.agg_sigma_sq = float(np.sum(weights ** weight_power * (sigma_sqs + disagreement)))\n",
        "\n",
        "\n",
        "class BayesianMCTSWithPower:\n",
        "    \"\"\"\n",
        "    Bayesian MCTS with configurable weight power in variance aggregation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        game: Game,\n",
        "        config: BayesianMCTSConfig,\n",
        "        weight_power: float = 2.0,  # NEW PARAMETER\n",
        "        use_transposition_table: bool = True\n",
        "    ):\n",
        "        self.game = game\n",
        "        self.config = config\n",
        "        self.weight_power = weight_power\n",
        "        self.use_tt = use_transposition_table\n",
        "        self.tt = TranspositionTable(game) if use_transposition_table else None\n",
        "\n",
        "    def clear_cache(self):\n",
        "        if self.tt:\n",
        "            self.tt.clear()\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        states: np.ndarray,\n",
        "        model: torch.nn.Module,\n",
        "        num_simulations: Optional[int] = None\n",
        "    ) -> np.ndarray:\n",
        "        if num_simulations is None:\n",
        "            num_simulations = self.config.num_simulations\n",
        "\n",
        "        num_states = states.shape[0]\n",
        "        device = next(model.parameters()).device\n",
        "        policies = np.zeros((num_states, self.game.config.action_size), dtype=np.float32)\n",
        "\n",
        "        # Handle terminal states\n",
        "        non_terminal_indices = []\n",
        "        non_terminal_states = []\n",
        "        for i in range(num_states):\n",
        "            if self.game.is_terminal(states[i]):\n",
        "                legal = self.game.legal_actions(states[i])\n",
        "                if legal:\n",
        "                    for a in legal:\n",
        "                        policies[i, a] = 1.0 / len(legal)\n",
        "            else:\n",
        "                non_terminal_indices.append(i)\n",
        "                non_terminal_states.append(states[i])\n",
        "\n",
        "        if not non_terminal_states:\n",
        "            return policies\n",
        "\n",
        "        # Batch expand roots\n",
        "        non_terminal_states_arr = np.stack(non_terminal_states)\n",
        "        roots, _ = self._batch_expand_roots(non_terminal_states_arr, model, device)\n",
        "\n",
        "        # Simulation loop\n",
        "        for sim in range(num_simulations):\n",
        "            leaves_to_expand = []\n",
        "            terminal_backups = []\n",
        "            expansion_backups = []\n",
        "\n",
        "            for local_idx in range(len(roots)):\n",
        "                root = roots[local_idx]\n",
        "                state = non_terminal_states[local_idx]\n",
        "                leaf_node, search_path, leaf_state, is_terminal = self._select_to_leaf(root, state)\n",
        "\n",
        "                if is_terminal:\n",
        "                    value = self.game.terminal_reward(leaf_state)\n",
        "                    terminal_backups.append((local_idx, search_path, value))\n",
        "                elif not leaf_node.expanded():\n",
        "                    leaves_to_expand.append((local_idx, leaf_node, leaf_state))\n",
        "                    expansion_backups.append((local_idx, search_path))\n",
        "\n",
        "            # Batch expand\n",
        "            if leaves_to_expand:\n",
        "                nodes = [item[1] for item in leaves_to_expand]\n",
        "                leaf_states = [item[2] for item in leaves_to_expand]\n",
        "                values = self._batch_expand_leaves(nodes, leaf_states, model, device)\n",
        "\n",
        "                for (local_idx, search_path), value in zip(expansion_backups, values):\n",
        "                    self._backup(search_path, value)\n",
        "\n",
        "            for local_idx, search_path, value in terminal_backups:\n",
        "                self._backup(search_path, value)\n",
        "\n",
        "        # Extract policies\n",
        "        for local_idx, state_idx in enumerate(non_terminal_indices):\n",
        "            policies[state_idx] = self._get_policy(roots[local_idx])\n",
        "\n",
        "        return policies\n",
        "\n",
        "    def _select_to_leaf(\n",
        "        self,\n",
        "        root: BayesianNodeWithPower,\n",
        "        state: np.ndarray\n",
        "    ) -> Tuple[BayesianNodeWithPower, List[Tuple[BayesianNodeWithPower, int]], np.ndarray, bool]:\n",
        "        node = root\n",
        "        search_path = []\n",
        "        current_state = state.copy()\n",
        "\n",
        "        while node.expanded() and not self.game.is_terminal(current_state):\n",
        "            action, child = self._select_child_thompson_ids(node)\n",
        "            search_path.append((node, action))\n",
        "            current_state = self.game.next_state(current_state, action)\n",
        "            node = child\n",
        "\n",
        "        is_terminal = self.game.is_terminal(current_state)\n",
        "        return node, search_path, current_state, is_terminal\n",
        "\n",
        "    def _create_children_from_policy(\n",
        "        self,\n",
        "        node: BayesianNodeWithPower,\n",
        "        state: np.ndarray,\n",
        "        policy: np.ndarray,\n",
        "        value: float\n",
        "    ) -> None:\n",
        "        legal_actions = self.game.legal_actions(state)\n",
        "        sigma_0 = self.config.sigma_0\n",
        "\n",
        "        eps = 1e-8\n",
        "        legal_probs = np.array([policy[a] for a in legal_actions])\n",
        "        legal_probs = legal_probs / (legal_probs.sum() + eps)\n",
        "        log_probs = np.log(legal_probs + eps)\n",
        "        entropy = -np.sum(legal_probs * log_probs)\n",
        "        scale = sigma_0 * (math.sqrt(6) / math.pi)\n",
        "\n",
        "        for i, action in enumerate(legal_actions):\n",
        "            mu = -value - scale * (log_probs[i] + entropy)\n",
        "            sigma_sq = sigma_0 ** 2\n",
        "            node.children[action] = BayesianNodeWithPower(\n",
        "                prior=policy[action],\n",
        "                mu=mu,\n",
        "                sigma_sq=sigma_sq\n",
        "            )\n",
        "\n",
        "    def _batch_expand_leaves(\n",
        "        self,\n",
        "        nodes: List[BayesianNodeWithPower],\n",
        "        states: List[np.ndarray],\n",
        "        model: torch.nn.Module,\n",
        "        device: torch.device\n",
        "    ) -> List[float]:\n",
        "        batch_size = len(nodes)\n",
        "        if batch_size == 0:\n",
        "            return []\n",
        "\n",
        "        results = [None] * batch_size\n",
        "        miss_indices = []\n",
        "        miss_canonical_keys = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            state = states[i]\n",
        "            node = nodes[i]\n",
        "\n",
        "            if self.tt:\n",
        "                cached = self.tt.get(state)\n",
        "                if cached is not None:\n",
        "                    policy, value = cached\n",
        "                    self._create_children_from_policy(node, state, policy, value)\n",
        "                    node.aggregate_children(self.config.prune_threshold, weight_power=self.weight_power)\n",
        "                    results[i] = value\n",
        "                    continue\n",
        "\n",
        "            if self.tt:\n",
        "                canonical_key, _ = self.tt._canonical_key(state)\n",
        "                miss_canonical_keys.append(canonical_key)\n",
        "            miss_indices.append(i)\n",
        "\n",
        "        if miss_indices:\n",
        "            if self.tt and miss_canonical_keys:\n",
        "                unique_keys = {}\n",
        "                for j, (idx, key) in enumerate(zip(miss_indices, miss_canonical_keys)):\n",
        "                    if key not in unique_keys:\n",
        "                        unique_keys[key] = j\n",
        "                unique_local_indices = list(unique_keys.values())\n",
        "            else:\n",
        "                unique_local_indices = list(range(len(miss_indices)))\n",
        "\n",
        "            unique_states = [states[miss_indices[j]] for j in unique_local_indices]\n",
        "\n",
        "            state_tensors = torch.stack([\n",
        "                self.game.to_tensor(self.game.canonical_state(s)) for s in unique_states\n",
        "            ]).to(device)\n",
        "\n",
        "            action_masks = torch.stack([\n",
        "                torch.from_numpy(self.game.legal_actions_mask(s))\n",
        "                for s in unique_states\n",
        "            ]).float().to(device)\n",
        "\n",
        "            policies, values = model.predict(state_tensors, action_masks)\n",
        "            policies = policies.cpu().numpy()\n",
        "            values = values.cpu().numpy().flatten()\n",
        "\n",
        "            if self.tt:\n",
        "                for j, state in enumerate(unique_states):\n",
        "                    self.tt.put(state, policies[j], values[j])\n",
        "\n",
        "            for idx in miss_indices:\n",
        "                state = states[idx]\n",
        "                node = nodes[idx]\n",
        "\n",
        "                if self.tt:\n",
        "                    policy, value = self.tt.get(state)\n",
        "                else:\n",
        "                    local_idx = miss_indices.index(idx)\n",
        "                    policy = policies[local_idx]\n",
        "                    value = values[local_idx]\n",
        "\n",
        "                self._create_children_from_policy(node, state, policy, value)\n",
        "                node.aggregate_children(self.config.prune_threshold, weight_power=self.weight_power)\n",
        "                results[idx] = value\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _batch_expand_roots(\n",
        "        self,\n",
        "        states: np.ndarray,\n",
        "        model: torch.nn.Module,\n",
        "        device: torch.device\n",
        "    ) -> Tuple[List[BayesianNodeWithPower], np.ndarray]:\n",
        "        batch_size = states.shape[0]\n",
        "        roots = [BayesianNodeWithPower() for _ in range(batch_size)]\n",
        "\n",
        "        cache_hits = [None] * batch_size\n",
        "        miss_indices = []\n",
        "\n",
        "        if self.tt:\n",
        "            for i in range(batch_size):\n",
        "                cached = self.tt.get(states[i])\n",
        "                if cached is not None:\n",
        "                    cache_hits[i] = cached\n",
        "                else:\n",
        "                    miss_indices.append(i)\n",
        "        else:\n",
        "            miss_indices = list(range(batch_size))\n",
        "\n",
        "        if miss_indices:\n",
        "            miss_states = np.stack([states[i] for i in miss_indices])\n",
        "\n",
        "            state_tensors = torch.stack([\n",
        "                self.game.to_tensor(self.game.canonical_state(s)) for s in miss_states\n",
        "            ]).to(device)\n",
        "\n",
        "            action_masks = torch.stack([\n",
        "                torch.from_numpy(self.game.legal_actions_mask(s))\n",
        "                for s in miss_states\n",
        "            ]).float().to(device)\n",
        "\n",
        "            policies, values = model.predict(state_tensors, action_masks)\n",
        "            policies = policies.cpu().numpy()\n",
        "            values = values.cpu().numpy().flatten()\n",
        "\n",
        "            for j, idx in enumerate(miss_indices):\n",
        "                if self.tt:\n",
        "                    self.tt.put(states[idx], policies[j], values[j])\n",
        "                cache_hits[idx] = (policies[j], values[j])\n",
        "\n",
        "        all_values = np.zeros(batch_size, dtype=np.float32)\n",
        "        for i, root in enumerate(roots):\n",
        "            policy, value = cache_hits[i]\n",
        "            self._create_children_from_policy(root, states[i], policy, value)\n",
        "            root.aggregate_children(self.config.prune_threshold, weight_power=self.weight_power)\n",
        "            all_values[i] = value\n",
        "\n",
        "        return roots, all_values\n",
        "\n",
        "    def _select_child_thompson_ids(\n",
        "        self,\n",
        "        node: BayesianNodeWithPower\n",
        "    ) -> Tuple[int, BayesianNodeWithPower]:\n",
        "        children = list(node.children.items())\n",
        "        if len(children) == 1:\n",
        "            return children[0]\n",
        "\n",
        "        samples = [(action, child, -child.sample()) for action, child in children]\n",
        "        samples.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        leader_action, leader_node, _ = samples[0]\n",
        "        challenger_action, challenger_node, _ = samples[1]\n",
        "\n",
        "        alpha = self.config.ids_alpha\n",
        "        precision_i = leader_node.precision()\n",
        "        precision_j = challenger_node.precision()\n",
        "\n",
        "        beta = (precision_i + alpha) / (precision_i + precision_j + 2 * alpha)\n",
        "\n",
        "        if np.random.random() < beta:\n",
        "            return challenger_action, challenger_node\n",
        "        else:\n",
        "            return leader_action, leader_node\n",
        "\n",
        "    def _backup(\n",
        "        self,\n",
        "        search_path: List[Tuple[BayesianNodeWithPower, int]],\n",
        "        leaf_value: float\n",
        "    ) -> None:\n",
        "        for i, (parent, action) in enumerate(reversed(search_path)):\n",
        "            child = parent.children[action]\n",
        "            child.visits += 1\n",
        "\n",
        "            if i == 0:\n",
        "                if not child.expanded():\n",
        "                    child.update(leaf_value, self.config.obs_var, self.config.min_variance)\n",
        "                else:\n",
        "                    if child.agg_mu is not None:\n",
        "                        child.mu = child.agg_mu\n",
        "                        child.sigma_sq = child.agg_sigma_sq\n",
        "\n",
        "            parent.aggregate_children(self.config.prune_threshold, visited_only=True, weight_power=self.weight_power)\n",
        "\n",
        "            if parent.agg_mu is not None:\n",
        "                parent.mu = parent.agg_mu\n",
        "                parent.sigma_sq = parent.agg_sigma_sq\n",
        "\n",
        "    def _get_policy(self, root: BayesianNodeWithPower) -> np.ndarray:\n",
        "        policy = np.zeros(self.game.config.action_size, dtype=np.float32)\n",
        "\n",
        "        if not root.expanded():\n",
        "            return policy\n",
        "\n",
        "        actions = list(root.children.keys())\n",
        "        children = [root.children[a] for a in actions]\n",
        "        n = len(children)\n",
        "\n",
        "        if n == 1:\n",
        "            policy[actions[0]] = 1.0\n",
        "            return policy\n",
        "\n",
        "        mus = np.array([-c.mu for c in children])\n",
        "        sigma_sqs = np.array([c.sigma_sq for c in children])\n",
        "\n",
        "        sorted_idx = np.argsort(mus)[::-1]\n",
        "        leader_idx = sorted_idx[0]\n",
        "        challenger_idx = sorted_idx[1]\n",
        "\n",
        "        scores = np.zeros(n)\n",
        "        mu_L, sigma_sq_L = mus[leader_idx], sigma_sqs[leader_idx]\n",
        "        mu_C, sigma_sq_C = mus[challenger_idx], sigma_sqs[challenger_idx]\n",
        "\n",
        "        for i in range(n):\n",
        "            if i == leader_idx:\n",
        "                diff = mu_L - mu_C\n",
        "                std = math.sqrt(sigma_sq_L + sigma_sq_C)\n",
        "            else:\n",
        "                diff = mus[i] - mu_L\n",
        "                std = math.sqrt(sigma_sqs[i] + sigma_sq_L)\n",
        "\n",
        "            if std > 1e-10:\n",
        "                scores[i] = normal_cdf(diff / std)\n",
        "            else:\n",
        "                scores[i] = 1.0 if diff > 0 else 0.0\n",
        "\n",
        "        total = scores.sum()\n",
        "        if total < 1e-10:\n",
        "            for action in actions:\n",
        "                policy[action] = 1.0 / n\n",
        "        else:\n",
        "            for i, action in enumerate(actions):\n",
        "                policy[action] = scores[i] / total\n",
        "\n",
        "        return policy\n",
        "\n",
        "\n",
        "print(\"BayesianMCTSWithPower class defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Arena Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanozero.game import get_game\n",
        "from nanozero.model import AlphaZeroTransformer\n",
        "from nanozero.mcts import BatchedMCTS, sample_action\n",
        "from nanozero.config import get_model_config, MCTSConfig, BayesianMCTSConfig\n",
        "from nanozero.common import load_checkpoint\n",
        "\n",
        "\n",
        "def run_arena(game, model, puct_mcts, ttts_mcts, num_games, mcts_simulations):\n",
        "    \"\"\"\n",
        "    Run arena between PUCT and TTTS, return results from TTTS perspective.\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (wins, draws, losses) for TTTS\n",
        "    \"\"\"\n",
        "    wins, draws, losses = 0, 0, 0\n",
        "\n",
        "    for i in range(num_games):\n",
        "        state = game.initial_state()\n",
        "        ttts_turn = 1 if i % 2 == 0 else -1  # Alternate who goes first\n",
        "\n",
        "        while not game.is_terminal(state):\n",
        "            current = game.current_player(state)\n",
        "            if current == ttts_turn:\n",
        "                policy = ttts_mcts.search(\n",
        "                    state[np.newaxis, ...], model,\n",
        "                    num_simulations=mcts_simulations\n",
        "                )[0]\n",
        "            else:\n",
        "                policy = puct_mcts.search(\n",
        "                    state[np.newaxis, ...], model,\n",
        "                    num_simulations=mcts_simulations, add_noise=False\n",
        "                )[0]\n",
        "            action = sample_action(policy, temperature=0)\n",
        "            state = game.next_state(state, action)\n",
        "\n",
        "        reward = game.terminal_reward(state)\n",
        "        final_player = game.current_player(state)\n",
        "\n",
        "        if final_player == ttts_turn:\n",
        "            ttts_result = reward\n",
        "        else:\n",
        "            ttts_result = -reward\n",
        "\n",
        "        if ttts_result > 0:\n",
        "            wins += 1\n",
        "        elif ttts_result < 0:\n",
        "            losses += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "\n",
        "    return wins, draws, losses\n",
        "\n",
        "\n",
        "print(\"Arena function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Run Ablation: Test Different Weight Powers\n",
        "\n",
        "Test powers from 1.0 to 2.0 in increments of 0.25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "game = get_game('connect4', use_rust=True)\n",
        "print(f\"Game backend: {game.backend}\")\n",
        "\n",
        "model_config = get_model_config(game.config, n_layer=4)\n",
        "model = AlphaZeroTransformer(model_config).to(device)\n",
        "load_checkpoint('checkpoints/connect4_final.pt', model)\n",
        "model.eval()\n",
        "\n",
        "# Setup PUCT baseline\n",
        "puct_config = MCTSConfig()\n",
        "puct_mcts = BatchedMCTS(game, puct_config)\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ablation configuration\n",
        "weight_powers = [1.0, 1.25, 1.5, 1.75, 2.0]\n",
        "num_games = 100  # Per configuration\n",
        "mcts_simulations = 100\n",
        "seed = 42\n",
        "\n",
        "print(f\"\\nWeight Power Ablation\")\n",
        "print(f\"=====================\")\n",
        "print(f\"Games per config: {num_games}\")\n",
        "print(f\"Simulations: {mcts_simulations}\")\n",
        "print(f\"Config: sigma_0=1.0, obs_var=1.0\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "results = []\n",
        "\n",
        "for power in weight_powers:\n",
        "    # Create TTTS with this weight power\n",
        "    ttts_config = BayesianMCTSConfig(\n",
        "        sigma_0=1.0,\n",
        "        obs_var=1.0,\n",
        "    )\n",
        "    ttts_mcts = BayesianMCTSWithPower(game, ttts_config, weight_power=power)\n",
        "    \n",
        "    # Clear caches\n",
        "    puct_mcts.clear_cache()\n",
        "    ttts_mcts.clear_cache()\n",
        "    \n",
        "    # Set seed for reproducibility\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    # Run arena\n",
        "    wins, draws, losses = run_arena(\n",
        "        game, model, puct_mcts, ttts_mcts,\n",
        "        num_games=num_games, mcts_simulations=mcts_simulations\n",
        "    )\n",
        "    \n",
        "    decisive = wins + losses\n",
        "    win_rate = wins / decisive if decisive > 0 else 0.5\n",
        "    \n",
        "    results.append({\n",
        "        'power': power,\n",
        "        'wins': wins,\n",
        "        'draws': draws,\n",
        "        'losses': losses,\n",
        "        'win_rate': win_rate,\n",
        "    })\n",
        "    \n",
        "    print(f\"p={power:.2f}: {wins}W/{draws}D/{losses}L  ({win_rate:.1%} decisive win rate)\")\n",
        "\n",
        "print(\"\\nAblation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "powers = [r['power'] for r in results]\n",
        "win_rates = [r['win_rate'] for r in results]\n",
        "wins = [r['wins'] for r in results]\n",
        "draws = [r['draws'] for r in results]\n",
        "losses = [r['losses'] for r in results]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Win rate plot\n",
        "ax1.plot(powers, win_rates, 'bo-', linewidth=2, markersize=10)\n",
        "ax1.axhline(y=0.5, color='gray', linestyle='--', label='50% baseline')\n",
        "ax1.set_xlabel('Weight Power (p)', fontsize=12)\n",
        "ax1.set_ylabel('TTTS Win Rate vs PUCT', fontsize=12)\n",
        "ax1.set_title('Win Rate by Weight Power', fontsize=14)\n",
        "ax1.set_ylim(0.3, 0.7)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Stacked bar chart\n",
        "x = np.arange(len(powers))\n",
        "width = 0.6\n",
        "\n",
        "ax2.bar(x, wins, width, label='Wins', color='green', alpha=0.8)\n",
        "ax2.bar(x, draws, width, bottom=wins, label='Draws', color='gray', alpha=0.8)\n",
        "ax2.bar(x, losses, width, bottom=[w+d for w, d in zip(wins, draws)], label='Losses', color='red', alpha=0.8)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels([f'p={p}' for p in powers])\n",
        "ax2.set_xlabel('Weight Power', fontsize=12)\n",
        "ax2.set_ylabel('Games', fontsize=12)\n",
        "ax2.set_title('Game Outcomes by Weight Power', fontsize=14)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('weight_power_ablation.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Find best power\n",
        "best_idx = np.argmax(win_rates)\n",
        "best_power = powers[best_idx]\n",
        "best_win_rate = win_rates[best_idx]\n",
        "\n",
        "print(f\"\\nBest weight power: p={best_power:.2f} ({best_win_rate:.1%} win rate)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Extended Ablation: Multiple Simulation Counts\n",
        "\n",
        "Test best weight powers across different simulation counts to see if optimal `p` varies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extended ablation with different sim counts\n",
        "weight_powers = [1.0, 1.5, 2.0]  # Just test the extremes and middle\n",
        "sim_counts = [50, 100, 200]\n",
        "num_games = 60  # Fewer games per cell for faster testing\n",
        "\n",
        "print(f\"\\nExtended Ablation: Weight Power x Simulation Count\")\n",
        "print(f\"=\"*60)\n",
        "\n",
        "extended_results = []\n",
        "\n",
        "for n_sims in sim_counts:\n",
        "    print(f\"\\n--- {n_sims} simulations ---\")\n",
        "    for power in weight_powers:\n",
        "        ttts_config = BayesianMCTSConfig(\n",
        "            sigma_0=1.0,\n",
        "            obs_var=1.0,\n",
        "        )\n",
        "        ttts_mcts = BayesianMCTSWithPower(game, ttts_config, weight_power=power)\n",
        "        \n",
        "        puct_mcts.clear_cache()\n",
        "        ttts_mcts.clear_cache()\n",
        "        \n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        \n",
        "        wins, draws, losses = run_arena(\n",
        "            game, model, puct_mcts, ttts_mcts,\n",
        "            num_games=num_games, mcts_simulations=n_sims\n",
        "        )\n",
        "        \n",
        "        decisive = wins + losses\n",
        "        win_rate = wins / decisive if decisive > 0 else 0.5\n",
        "        \n",
        "        extended_results.append({\n",
        "            'n_sims': n_sims,\n",
        "            'power': power,\n",
        "            'wins': wins,\n",
        "            'draws': draws,\n",
        "            'losses': losses,\n",
        "            'win_rate': win_rate,\n",
        "        })\n",
        "        \n",
        "        print(f\"  p={power:.1f}: {wins}W/{draws}D/{losses}L ({win_rate:.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize extended results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "for power in weight_powers:\n",
        "    power_results = [r for r in extended_results if r['power'] == power]\n",
        "    sims = [r['n_sims'] for r in power_results]\n",
        "    rates = [r['win_rate'] for r in power_results]\n",
        "    ax.plot(sims, rates, 'o-', linewidth=2, markersize=8, label=f'p={power}')\n",
        "\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', label='50% baseline')\n",
        "ax.set_xlabel('MCTS Simulations', fontsize=12)\n",
        "ax.set_ylabel('TTTS Win Rate vs PUCT', fontsize=12)\n",
        "ax.set_title('Weight Power Effect Across Simulation Counts', fontsize=14)\n",
        "ax.set_ylim(0.3, 0.7)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('weight_power_vs_sims.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "### Theory\n",
        "\n",
        "The variance aggregation formula:\n",
        "```\n",
        "agg_sigma_sq = sum(w^p * (sigma_sq + disagreement))\n",
        "```\n",
        "\n",
        "- **p=2 (current)**: Correct if children's values are independent random variables\n",
        "- **p=1**: Correct if children's values are perfectly correlated\n",
        "- **1 < p < 2**: Appropriate for partial correlation\n",
        "\n",
        "### Results Interpretation\n",
        "\n",
        "1. **If p=2 is best**: Children's values are approximately independent (search explores different regions)\n",
        "2. **If p=1 is best**: Children's values are highly correlated (NN errors are systematic)\n",
        "3. **If intermediate p is best**: Moderate correlation exists\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "If an intermediate value of `p` performs best:\n",
        "1. Add `weight_power` parameter to `BayesianMCTSConfig`\n",
        "2. Update `aggregate_children` to use the parameter\n",
        "3. Consider making `p` adaptive based on tree depth or visit count"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
