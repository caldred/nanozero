{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTTS vs PUCT Arena Testing\n",
    "\n",
    "Test Bayesian MCTS (TTTS-IDS) against standard PUCT at various simulation counts.\n",
    "\n",
    "**Setup:** Use `Runtime > Change runtime type > A100 GPU` for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Rust toolchain\n",
    "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
    "import os\n",
    "os.environ[\"PATH\"] = f\"{os.environ['HOME']}/.cargo/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Verify Rust installation\n",
    "!rustc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/caldred/nanozero.git\n",
    "%cd nanozero\n",
    "\n",
    "# Install Python dependencies\n",
    "!pip install -q numpy scipy maturin\n",
    "\n",
    "# Build and install Rust extension\n",
    "%cd nanozero-mcts-rs\n",
    "!maturin build --release\n",
    "!pip install target/wheels/nanozero_mcts_rs-*.whl\n",
    "%cd ..\n",
    "\n",
    "# Verify Rust backend is available\n",
    "!python -c \"from nanozero.game import RUST_AVAILABLE; print(f'Rust backend available: {RUST_AVAILABLE}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload checkpoint: Use the file upload button or this cell\n",
    "# Option 1: Upload via Colab UI to checkpoints/connect4_iter150.pt\n",
    "# Option 2: Mount Google Drive if you have it there\n",
    "!mkdir -p checkpoints\n",
    "\n",
    "# Uncomment to mount Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp /content/drive/MyDrive/path/to/connect4_iter150.pt checkpoints/\n",
    "\n",
    "# Check if checkpoint exists\n",
    "import os\n",
    "if os.path.exists('checkpoints/connect4_iter150.pt'):\n",
    "    print(\"Checkpoint found!\")\n",
    "else:\n",
    "    print(\"Please upload checkpoints/connect4_iter150.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport torch\nfrom scipy import stats\nfrom nanozero.game import get_game\nfrom nanozero.model import AlphaZeroTransformer\nfrom nanozero.mcts import BatchedMCTS, BayesianMCTS\nfrom nanozero.common import sample_action\nfrom nanozero.config import get_model_config, MCTSConfig, BayesianMCTSConfig\nfrom nanozero.common import get_device, load_checkpoint\n\ndevice = get_device()\nprint(f\"Device: {device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load game and model\n",
    "game = get_game('connect4')\n",
    "print(f\"Game backend: {game.backend}\")\n",
    "\n",
    "model_config = get_model_config(game.config, n_layer=4)\n",
    "model = AlphaZeroTransformer(model_config).to(device)\n",
    "load_checkpoint('checkpoints/connect4_iter150.pt', model)\n",
    "model.eval()\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current TTTS config\n",
    "ttts_config = BayesianMCTSConfig()\n",
    "print(\"Current BayesianMCTSConfig:\")\n",
    "print(f\"  optimality_weight: {ttts_config.optimality_weight}\")\n",
    "print(f\"  adaptive_weight: {ttts_config.adaptive_weight}\")\n",
    "print(f\"  visit_scale: {ttts_config.visit_scale}\")\n",
    "print(f\"  prune_threshold: {ttts_config.prune_threshold}\")\n",
    "print(f\"  sigma_0: {ttts_config.sigma_0}\")\n",
    "print(f\"  obs_var: {ttts_config.obs_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_arena(game, model, puct_mcts, ttts_mcts, num_games, mcts_simulations):\n",
    "    \"\"\"Run arena, return results from TTTS perspective.\"\"\"\n",
    "\n",
    "    def make_puct_player():\n",
    "        def play(state):\n",
    "            policy = puct_mcts.search(\n",
    "                state[np.newaxis, ...], model,\n",
    "                num_simulations=mcts_simulations, add_noise=False\n",
    "            )[0]\n",
    "            return sample_action(policy, temperature=0)\n",
    "        return play\n",
    "\n",
    "    def make_ttts_player():\n",
    "        def play(state):\n",
    "            policy = ttts_mcts.search(\n",
    "                state[np.newaxis, ...], model,\n",
    "                num_simulations=mcts_simulations\n",
    "            )[0]\n",
    "            return sample_action(policy, temperature=0)\n",
    "        return play\n",
    "\n",
    "    ttts_player = make_ttts_player()\n",
    "    puct_player = make_puct_player()\n",
    "\n",
    "    wins, draws, losses = 0, 0, 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        state = game.initial_state()\n",
    "        ttts_turn = 1 if i % 2 == 0 else -1\n",
    "\n",
    "        while not game.is_terminal(state):\n",
    "            current = game.current_player(state)\n",
    "            if current == ttts_turn:\n",
    "                action = ttts_player(state)\n",
    "            else:\n",
    "                action = puct_player(state)\n",
    "            state = game.next_state(state, action)\n",
    "\n",
    "        reward = game.terminal_reward(state)\n",
    "        final_player = game.current_player(state)\n",
    "\n",
    "        if final_player == ttts_turn:\n",
    "            ttts_result = reward\n",
    "        else:\n",
    "            ttts_result = -reward\n",
    "\n",
    "        if ttts_result > 0:\n",
    "            wins += 1\n",
    "        elif ttts_result < 0:\n",
    "            losses += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Progress: {i+1}/{num_games}\")\n",
    "\n",
    "    return wins, draws, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Arena at different simulation counts\n",
    "\n",
    "Test TTTS vs PUCT at 50, 100, 200, 400 simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run arena at different simulation counts\n",
    "puct_config = MCTSConfig()\n",
    "puct_mcts = BatchedMCTS(game, puct_config)\n",
    "\n",
    "ttts_config = BayesianMCTSConfig()\n",
    "ttts_mcts = BayesianMCTS(game, ttts_config)\n",
    "\n",
    "num_games = 100\n",
    "results = {}\n",
    "\n",
    "for n_sims in [50, 100, 200, 400]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testing with {n_sims} simulations\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    wins, draws, losses = run_arena(\n",
    "        game, model, puct_mcts, ttts_mcts,\n",
    "        num_games=num_games, mcts_simulations=n_sims\n",
    "    )\n",
    "    \n",
    "    decisive = wins + losses\n",
    "    win_rate = wins / decisive if decisive > 0 else 0\n",
    "    \n",
    "    # Binomial test\n",
    "    if decisive > 0:\n",
    "        p_value = stats.binomtest(wins, decisive, 0.5).pvalue\n",
    "    else:\n",
    "        p_value = 1.0\n",
    "    \n",
    "    results[n_sims] = {\n",
    "        'wins': wins, 'draws': draws, 'losses': losses,\n",
    "        'win_rate': win_rate, 'p_value': p_value\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nResults: TTTS {wins}W / {draws}D / {losses}L\")\n",
    "    print(f\"Decisive win rate: {win_rate:.1%}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: TTTS vs PUCT (TTTS perspective)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Sims':<8} {'Wins':<8} {'Draws':<8} {'Losses':<8} {'Win%':<10} {'p-value':<10}\")\n",
    "print(\"-\"*60)\n",
    "for n_sims, r in results.items():\n",
    "    sig = \"*\" if r['p_value'] < 0.05 else \"\"\n",
    "    print(f\"{n_sims:<8} {r['wins']:<8} {r['draws']:<8} {r['losses']:<8} {r['win_rate']:.1%:<10} {r['p_value']:.4f}{sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Sweep optimality_weight values\n",
    "\n",
    "Try different base optimality weights to find a better balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different optimality weights at 200 sims\n",
    "n_sims = 200\n",
    "num_games = 50\n",
    "\n",
    "weight_results = {}\n",
    "\n",
    "for opt_weight in [0.0, 0.3, 0.5, 0.7, 1.0]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"optimality_weight = {opt_weight}, adaptive = True\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    ttts_config = BayesianMCTSConfig(\n",
    "        optimality_weight=opt_weight,\n",
    "        adaptive_weight=True,\n",
    "        visit_scale=50.0\n",
    "    )\n",
    "    ttts_mcts = BayesianMCTS(game, ttts_config)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    wins, draws, losses = run_arena(\n",
    "        game, model, puct_mcts, ttts_mcts,\n",
    "        num_games=num_games, mcts_simulations=n_sims\n",
    "    )\n",
    "    \n",
    "    decisive = wins + losses\n",
    "    win_rate = wins / decisive if decisive > 0 else 0\n",
    "    \n",
    "    weight_results[opt_weight] = {\n",
    "        'wins': wins, 'draws': draws, 'losses': losses,\n",
    "        'win_rate': win_rate\n",
    "    }\n",
    "    \n",
    "    print(f\"Results: TTTS {wins}W / {draws}D / {losses}L ({win_rate:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of weight sweep\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"WEIGHT SWEEP @ {n_sims} sims (adaptive=True)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Weight':<10} {'Wins':<8} {'Draws':<8} {'Losses':<8} {'Win%':<10}\")\n",
    "print(\"-\"*50)\n",
    "for w, r in weight_results.items():\n",
    "    print(f\"{w:<10} {r['wins']:<8} {r['draws']:<8} {r['losses']:<8} {r['win_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Adaptive vs non-adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare adaptive vs non-adaptive at best weight\n",
    "n_sims = 200\n",
    "num_games = 50\n",
    "opt_weight = 0.5  # Try the middle value\n",
    "\n",
    "adaptive_results = {}\n",
    "\n",
    "for adaptive in [False, True]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"optimality_weight = {opt_weight}, adaptive = {adaptive}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    ttts_config = BayesianMCTSConfig(\n",
    "        optimality_weight=opt_weight,\n",
    "        adaptive_weight=adaptive,\n",
    "        visit_scale=50.0\n",
    "    )\n",
    "    ttts_mcts = BayesianMCTS(game, ttts_config)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    wins, draws, losses = run_arena(\n",
    "        game, model, puct_mcts, ttts_mcts,\n",
    "        num_games=num_games, mcts_simulations=n_sims\n",
    "    )\n",
    "    \n",
    "    decisive = wins + losses\n",
    "    win_rate = wins / decisive if decisive > 0 else 0\n",
    "    \n",
    "    adaptive_results[adaptive] = {\n",
    "        'wins': wins, 'draws': draws, 'losses': losses,\n",
    "        'win_rate': win_rate\n",
    "    }\n",
    "    \n",
    "    print(f\"Results: TTTS {wins}W / {draws}D / {losses}L ({win_rate:.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"ADAPTIVE COMPARISON @ {n_sims} sims, weight={opt_weight}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Adaptive':<10} {'Wins':<8} {'Draws':<8} {'Losses':<8} {'Win%':<10}\")\n",
    "print(\"-\"*50)\n",
    "for a, r in adaptive_results.items():\n",
    "    print(f\"{str(a):<10} {r['wins']:<8} {r['draws']:<8} {r['losses']:<8} {r['win_rate']:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}