{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Visited-Only Ablation: Prior Inclusion in Bayesian MCTS Backup\n",
    "\n",
    "This notebook tests whether unvisited children's prior beliefs should be included during backup.\n",
    "\n",
    "## Background\n",
    "\n",
    "`aggregate_children()` is called in two contexts:\n",
    "\n",
    "1. **At expansion** (default `visited_only=False`): All newly-created children are included\n",
    "2. **During backup** (currently `visited_only=True`): Only visited children are aggregated\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "Including unvisited children's priors (`visited_only=False` in backup) might:\n",
    "- **Help** when search is shallow (many unvisited children with informative NN priors)\n",
    "- **Hurt** when unvisited children have high variance that dilutes the signal\n",
    "\n",
    "## Experiments\n",
    "\n",
    "1. **visited_only=True vs False** in backup step\n",
    "2. **Hybrid approaches**: Weight by visit count, or only include high-prior unvisited children\n",
    "3. **Varying simulation counts**: See if optimal setting changes with search depth\n",
    "\n",
    "**Setup:** Use `Runtime > Change runtime type > GPU` for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Rust toolchain\n",
    "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
    "import os\n",
    "os.environ[\"PATH\"] = f\"{os.environ['HOME']}/.cargo/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "# Verify Rust installation\n",
    "!rustc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/caldred/nanozero.git\n",
    "%cd nanozero\n",
    "\n",
    "# Install Python dependencies\n",
    "!pip install -q numpy scipy maturin\n",
    "\n",
    "# Build and install Rust extension\n",
    "%cd nanozero-mcts-rs\n",
    "!maturin build --release\n",
    "!pip install target/wheels/nanozero_mcts_rs-*.whl\n",
    "%cd ..\n",
    "\n",
    "# Verify Rust backend is available\n",
    "!python -c \"from nanozero.game import HAS_RUST_GAMES; print(f'Rust backend available: {HAS_RUST_GAMES}')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Connect4 Model\n",
    "\n",
    "First, train a model we'll use for all ablation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Connect4 - A100 optimized settings\n",
    "# ~5-10 minutes on A100\n",
    "!python -m scripts.train \\\n",
    "    --game=connect4 \\\n",
    "    --n_layer=4 \\\n",
    "    --num_iterations=150 \\\n",
    "    --games_per_iteration=64 \\\n",
    "    --training_steps=200 \\\n",
    "    --mcts_simulations=100 \\\n",
    "    --batch_size=256 \\\n",
    "    --buffer_size=100000 \\\n",
    "    --parallel_games=128 \\\n",
    "    --eval_interval=25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Modified Bayesian MCTS with Configurable visited_only\n",
    "\n",
    "Create variants that use different `visited_only` strategies during backup:\n",
    "\n",
    "1. **visited_only=True** (current): Only aggregate visited children\n",
    "2. **visited_only=False**: Include all children's beliefs\n",
    "3. **Hybrid**: Weight by (visits + 1) pseudocount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from nanozero.config import BayesianMCTSConfig\n",
    "from nanozero.game import Game\n",
    "from nanozero.mcts import TranspositionTable\n",
    "\n",
    "\n",
    "def normal_cdf(x: float) -> float:\n",
    "    \"\"\"Standard normal CDF using error function.\"\"\"\n",
    "    return 0.5 * (1.0 + math.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "class BayesianNodeVisitedOnly:\n",
    "    \"\"\"\n",
    "    MCTS tree node with Gaussian belief over value.\n",
    "    Modified to support different visited_only strategies in aggregation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prior: float = 0.0, mu: float = 0.0, sigma_sq: float = 1.0):\n",
    "        self.prior = prior\n",
    "        self.mu = mu\n",
    "        self.sigma_sq = sigma_sq\n",
    "        self.children: Dict[int, 'BayesianNodeVisitedOnly'] = {}\n",
    "        self.agg_mu: Optional[float] = None\n",
    "        self.agg_sigma_sq: Optional[float] = None\n",
    "        self.visits: int = 0\n",
    "\n",
    "    def expanded(self) -> bool:\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def sample(self) -> float:\n",
    "        return np.random.normal(self.mu, math.sqrt(self.sigma_sq))\n",
    "\n",
    "    def update(self, value: float, obs_var: float, min_var: float = 1e-6) -> None:\n",
    "        precision_prior = 1.0 / max(self.sigma_sq, min_var)\n",
    "        precision_obs = 1.0 / max(obs_var, min_var)\n",
    "        new_precision = precision_prior + precision_obs\n",
    "        self.mu = (precision_prior * self.mu + precision_obs * value) / new_precision\n",
    "        self.sigma_sq = max(1.0 / new_precision, min_var)\n",
    "\n",
    "    def precision(self) -> float:\n",
    "        return 1.0 / self.sigma_sq\n",
    "\n",
    "    def aggregate_children(\n",
    "        self, \n",
    "        prune_threshold: float = 0.01, \n",
    "        visited_only: bool = False,\n",
    "        visit_weighted: bool = False  # NEW: weight by visits instead of binary filter\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Compute aggregated belief from children using optimality weights.\n",
    "        \n",
    "        Args:\n",
    "            prune_threshold: Children with P(optimal) < threshold get weight 0\n",
    "            visited_only: If True, only aggregate children that have been visited\n",
    "            visit_weighted: If True, weight children by (visits + 1) pseudocount\n",
    "        \"\"\"\n",
    "        if not self.children:\n",
    "            return\n",
    "\n",
    "        if visited_only:\n",
    "            children = [c for c in self.children.values() if c.visits > 0]\n",
    "            if not children:\n",
    "                return\n",
    "        else:\n",
    "            children = list(self.children.values())\n",
    "\n",
    "        n = len(children)\n",
    "\n",
    "        if n == 1:\n",
    "            child = children[0]\n",
    "            self.agg_mu = -child.mu\n",
    "            self.agg_sigma_sq = child.sigma_sq\n",
    "            return\n",
    "\n",
    "        # Get child beliefs from parent's perspective (negate child values)\n",
    "        mus = np.array([-c.mu for c in children])\n",
    "        sigma_sqs = np.array([c.sigma_sq for c in children])\n",
    "\n",
    "        # Find leader and challenger by mean\n",
    "        sorted_idx = np.argsort(mus)[::-1]\n",
    "        leader_idx = sorted_idx[0]\n",
    "        challenger_idx = sorted_idx[1]\n",
    "\n",
    "        # Compute optimality scores via pairwise Gaussian CDF comparisons\n",
    "        scores = np.zeros(n)\n",
    "        mu_L, sigma_sq_L = mus[leader_idx], sigma_sqs[leader_idx]\n",
    "        mu_C, sigma_sq_C = mus[challenger_idx], sigma_sqs[challenger_idx]\n",
    "\n",
    "        for i in range(n):\n",
    "            if i == leader_idx:\n",
    "                diff = mu_L - mu_C\n",
    "                std = math.sqrt(sigma_sq_L + sigma_sq_C)\n",
    "            else:\n",
    "                diff = mus[i] - mu_L\n",
    "                std = math.sqrt(sigma_sqs[i] + sigma_sq_L)\n",
    "\n",
    "            if std > 1e-10:\n",
    "                scores[i] = normal_cdf(diff / std)\n",
    "            else:\n",
    "                scores[i] = 1.0 if diff > 0 else 0.0\n",
    "\n",
    "        # Apply visit weighting if enabled\n",
    "        if visit_weighted:\n",
    "            # Weight by (visits + 1) to give unvisited children some weight\n",
    "            visit_weights = np.array([c.visits + 1 for c in children], dtype=np.float32)\n",
    "            scores = scores * visit_weights\n",
    "\n",
    "        # Soft prune and normalize\n",
    "        scores[scores < prune_threshold] = 0.0\n",
    "        total = scores.sum()\n",
    "        if total < 1e-10:\n",
    "            weights = np.ones(n) / n\n",
    "        else:\n",
    "            weights = scores / total\n",
    "\n",
    "        # Aggregated mean (weighted average of children)\n",
    "        self.agg_mu = float(np.sum(weights * mus))\n",
    "\n",
    "        # Aggregated variance (squared weights + disagreement term)\n",
    "        disagreement = (mus - self.agg_mu) ** 2\n",
    "        self.agg_sigma_sq = float(np.sum(weights ** 2 * (sigma_sqs + disagreement)))\n",
    "\n",
    "\n",
    "class BayesianMCTSVisitedOnly:\n",
    "    \"\"\"\n",
    "    Bayesian MCTS with configurable visited_only strategy during backup.\n",
    "    \n",
    "    backup_mode options:\n",
    "    - 'visited': Only aggregate visited children (current default)\n",
    "    - 'all': Aggregate all children including unvisited\n",
    "    - 'weighted': Aggregate all children weighted by (visits + 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        game: Game,\n",
    "        config: BayesianMCTSConfig,\n",
    "        backup_mode: str = 'visited',  # 'visited', 'all', or 'weighted'\n",
    "        use_transposition_table: bool = True\n",
    "    ):\n",
    "        self.game = game\n",
    "        self.config = config\n",
    "        self.backup_mode = backup_mode\n",
    "        self.use_tt = use_transposition_table\n",
    "        self.tt = TranspositionTable(game) if use_transposition_table else None\n",
    "\n",
    "    def clear_cache(self):\n",
    "        if self.tt:\n",
    "            self.tt.clear()\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        states: np.ndarray,\n",
    "        model: torch.nn.Module,\n",
    "        num_simulations: Optional[int] = None\n",
    "    ) -> np.ndarray:\n",
    "        if num_simulations is None:\n",
    "            num_simulations = self.config.num_simulations\n",
    "\n",
    "        num_states = states.shape[0]\n",
    "        device = next(model.parameters()).device\n",
    "        policies = np.zeros((num_states, self.game.config.action_size), dtype=np.float32)\n",
    "\n",
    "        # Handle terminal states\n",
    "        non_terminal_indices = []\n",
    "        non_terminal_states = []\n",
    "        for i in range(num_states):\n",
    "            if self.game.is_terminal(states[i]):\n",
    "                legal = self.game.legal_actions(states[i])\n",
    "                if legal:\n",
    "                    for a in legal:\n",
    "                        policies[i, a] = 1.0 / len(legal)\n",
    "            else:\n",
    "                non_terminal_indices.append(i)\n",
    "                non_terminal_states.append(states[i])\n",
    "\n",
    "        if not non_terminal_states:\n",
    "            return policies\n",
    "\n",
    "        # Batch expand roots\n",
    "        non_terminal_states_arr = np.stack(non_terminal_states)\n",
    "        roots, _ = self._batch_expand_roots(non_terminal_states_arr, model, device)\n",
    "\n",
    "        # Simulation loop\n",
    "        for sim in range(num_simulations):\n",
    "            leaves_to_expand = []\n",
    "            terminal_backups = []\n",
    "            expansion_backups = []\n",
    "\n",
    "            for local_idx in range(len(roots)):\n",
    "                root = roots[local_idx]\n",
    "                state = non_terminal_states[local_idx]\n",
    "                leaf_node, search_path, leaf_state, is_terminal = self._select_to_leaf(root, state)\n",
    "\n",
    "                if is_terminal:\n",
    "                    value = self.game.terminal_reward(leaf_state)\n",
    "                    terminal_backups.append((local_idx, search_path, value))\n",
    "                elif not leaf_node.expanded():\n",
    "                    leaves_to_expand.append((local_idx, leaf_node, leaf_state))\n",
    "                    expansion_backups.append((local_idx, search_path))\n",
    "\n",
    "            # Batch expand\n",
    "            if leaves_to_expand:\n",
    "                nodes = [item[1] for item in leaves_to_expand]\n",
    "                leaf_states = [item[2] for item in leaves_to_expand]\n",
    "                values = self._batch_expand_leaves(nodes, leaf_states, model, device)\n",
    "\n",
    "                for (local_idx, search_path), value in zip(expansion_backups, values):\n",
    "                    self._backup(search_path, value)\n",
    "\n",
    "            for local_idx, search_path, value in terminal_backups:\n",
    "                self._backup(search_path, value)\n",
    "\n",
    "        # Extract policies\n",
    "        for local_idx, state_idx in enumerate(non_terminal_indices):\n",
    "            policies[state_idx] = self._get_policy(roots[local_idx])\n",
    "\n",
    "        return policies\n",
    "\n",
    "    def _select_to_leaf(\n",
    "        self,\n",
    "        root: BayesianNodeVisitedOnly,\n",
    "        state: np.ndarray\n",
    "    ) -> Tuple[BayesianNodeVisitedOnly, List[Tuple[BayesianNodeVisitedOnly, int]], np.ndarray, bool]:\n",
    "        node = root\n",
    "        search_path = []\n",
    "        current_state = state.copy()\n",
    "\n",
    "        while node.expanded() and not self.game.is_terminal(current_state):\n",
    "            action, child = self._select_child_thompson_ids(node)\n",
    "            search_path.append((node, action))\n",
    "            current_state = self.game.next_state(current_state, action)\n",
    "            node = child\n",
    "\n",
    "        is_terminal = self.game.is_terminal(current_state)\n",
    "        return node, search_path, current_state, is_terminal\n",
    "\n",
    "    def _create_children_from_policy(\n",
    "        self,\n",
    "        node: BayesianNodeVisitedOnly,\n",
    "        state: np.ndarray,\n",
    "        policy: np.ndarray,\n",
    "        value: float\n",
    "    ) -> None:\n",
    "        legal_actions = self.game.legal_actions(state)\n",
    "        sigma_0 = self.config.sigma_0\n",
    "\n",
    "        eps = 1e-8\n",
    "        legal_probs = np.array([policy[a] for a in legal_actions])\n",
    "        legal_probs = legal_probs / (legal_probs.sum() + eps)\n",
    "        log_probs = np.log(legal_probs + eps)\n",
    "        entropy = -np.sum(legal_probs * log_probs)\n",
    "        scale = sigma_0 * (math.sqrt(6) / math.pi)\n",
    "\n",
    "        for i, action in enumerate(legal_actions):\n",
    "            mu = -value - scale * (log_probs[i] + entropy)\n",
    "            sigma_sq = sigma_0 ** 2\n",
    "            node.children[action] = BayesianNodeVisitedOnly(\n",
    "                prior=policy[action],\n",
    "                mu=mu,\n",
    "                sigma_sq=sigma_sq\n",
    "            )\n",
    "\n",
    "    def _batch_expand_leaves(\n",
    "        self,\n",
    "        nodes: List[BayesianNodeVisitedOnly],\n",
    "        states: List[np.ndarray],\n",
    "        model: torch.nn.Module,\n",
    "        device: torch.device\n",
    "    ) -> List[float]:\n",
    "        batch_size = len(nodes)\n",
    "        if batch_size == 0:\n",
    "            return []\n",
    "\n",
    "        results = [None] * batch_size\n",
    "        miss_indices = []\n",
    "        miss_canonical_keys = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            state = states[i]\n",
    "            node = nodes[i]\n",
    "\n",
    "            if self.tt:\n",
    "                cached = self.tt.get(state)\n",
    "                if cached is not None:\n",
    "                    policy, value = cached\n",
    "                    self._create_children_from_policy(node, state, policy, value)\n",
    "                    # At expansion: always use all children (visited_only=False)\n",
    "                    node.aggregate_children(self.config.prune_threshold)\n",
    "                    results[i] = value\n",
    "                    continue\n",
    "\n",
    "            if self.tt:\n",
    "                canonical_key, _ = self.tt._canonical_key(state)\n",
    "                miss_canonical_keys.append(canonical_key)\n",
    "            miss_indices.append(i)\n",
    "\n",
    "        if miss_indices:\n",
    "            if self.tt and miss_canonical_keys:\n",
    "                unique_keys = {}\n",
    "                for j, (idx, key) in enumerate(zip(miss_indices, miss_canonical_keys)):\n",
    "                    if key not in unique_keys:\n",
    "                        unique_keys[key] = j\n",
    "                unique_local_indices = list(unique_keys.values())\n",
    "            else:\n",
    "                unique_local_indices = list(range(len(miss_indices)))\n",
    "\n",
    "            unique_states = [states[miss_indices[j]] for j in unique_local_indices]\n",
    "\n",
    "            state_tensors = torch.stack([\n",
    "                self.game.to_tensor(self.game.canonical_state(s)) for s in unique_states\n",
    "            ]).to(device)\n",
    "\n",
    "            action_masks = torch.stack([\n",
    "                torch.from_numpy(self.game.legal_actions_mask(s))\n",
    "                for s in unique_states\n",
    "            ]).float().to(device)\n",
    "\n",
    "            policies, values = model.predict(state_tensors, action_masks)\n",
    "            policies = policies.cpu().numpy()\n",
    "            values = values.cpu().numpy().flatten()\n",
    "\n",
    "            if self.tt:\n",
    "                for j, state in enumerate(unique_states):\n",
    "                    self.tt.put(state, policies[j], values[j])\n",
    "\n",
    "            for idx in miss_indices:\n",
    "                state = states[idx]\n",
    "                node = nodes[idx]\n",
    "\n",
    "                if self.tt:\n",
    "                    policy, value = self.tt.get(state)\n",
    "                else:\n",
    "                    local_idx = miss_indices.index(idx)\n",
    "                    policy = policies[local_idx]\n",
    "                    value = values[local_idx]\n",
    "\n",
    "                self._create_children_from_policy(node, state, policy, value)\n",
    "                # At expansion: always use all children\n",
    "                node.aggregate_children(self.config.prune_threshold)\n",
    "                results[idx] = value\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _batch_expand_roots(\n",
    "        self,\n",
    "        states: np.ndarray,\n",
    "        model: torch.nn.Module,\n",
    "        device: torch.device\n",
    "    ) -> Tuple[List[BayesianNodeVisitedOnly], np.ndarray]:\n",
    "        batch_size = states.shape[0]\n",
    "        roots = [BayesianNodeVisitedOnly() for _ in range(batch_size)]\n",
    "\n",
    "        cache_hits = [None] * batch_size\n",
    "        miss_indices = []\n",
    "\n",
    "        if self.tt:\n",
    "            for i in range(batch_size):\n",
    "                cached = self.tt.get(states[i])\n",
    "                if cached is not None:\n",
    "                    cache_hits[i] = cached\n",
    "                else:\n",
    "                    miss_indices.append(i)\n",
    "        else:\n",
    "            miss_indices = list(range(batch_size))\n",
    "\n",
    "        if miss_indices:\n",
    "            miss_states = np.stack([states[i] for i in miss_indices])\n",
    "\n",
    "            state_tensors = torch.stack([\n",
    "                self.game.to_tensor(self.game.canonical_state(s)) for s in miss_states\n",
    "            ]).to(device)\n",
    "\n",
    "            action_masks = torch.stack([\n",
    "                torch.from_numpy(self.game.legal_actions_mask(s))\n",
    "                for s in miss_states\n",
    "            ]).float().to(device)\n",
    "\n",
    "            policies, values = model.predict(state_tensors, action_masks)\n",
    "            policies = policies.cpu().numpy()\n",
    "            values = values.cpu().numpy().flatten()\n",
    "\n",
    "            for j, idx in enumerate(miss_indices):\n",
    "                if self.tt:\n",
    "                    self.tt.put(states[idx], policies[j], values[j])\n",
    "                cache_hits[idx] = (policies[j], values[j])\n",
    "\n",
    "        all_values = np.zeros(batch_size, dtype=np.float32)\n",
    "        for i, root in enumerate(roots):\n",
    "            policy, value = cache_hits[i]\n",
    "            self._create_children_from_policy(root, states[i], policy, value)\n",
    "            # At expansion: always use all children\n",
    "            root.aggregate_children(self.config.prune_threshold)\n",
    "            all_values[i] = value\n",
    "\n",
    "        return roots, all_values\n",
    "\n",
    "    def _select_child_thompson_ids(\n",
    "        self,\n",
    "        node: BayesianNodeVisitedOnly\n",
    "    ) -> Tuple[int, BayesianNodeVisitedOnly]:\n",
    "        children = list(node.children.items())\n",
    "        if len(children) == 1:\n",
    "            return children[0]\n",
    "\n",
    "        samples = [(action, child, -child.sample()) for action, child in children]\n",
    "        samples.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        leader_action, leader_node, _ = samples[0]\n",
    "        challenger_action, challenger_node, _ = samples[1]\n",
    "\n",
    "        alpha = self.config.ids_alpha\n",
    "        precision_i = leader_node.precision()\n",
    "        precision_j = challenger_node.precision()\n",
    "\n",
    "        beta = (precision_i + alpha) / (precision_i + precision_j + 2 * alpha)\n",
    "\n",
    "        if np.random.random() < beta:\n",
    "            return challenger_action, challenger_node\n",
    "        else:\n",
    "            return leader_action, leader_node\n",
    "\n",
    "    def _backup(\n",
    "        self,\n",
    "        search_path: List[Tuple[BayesianNodeVisitedOnly, int]],\n",
    "        leaf_value: float\n",
    "    ) -> None:\n",
    "        # Determine aggregation parameters based on backup_mode\n",
    "        if self.backup_mode == 'visited':\n",
    "            visited_only = True\n",
    "            visit_weighted = False\n",
    "        elif self.backup_mode == 'all':\n",
    "            visited_only = False\n",
    "            visit_weighted = False\n",
    "        elif self.backup_mode == 'weighted':\n",
    "            visited_only = False\n",
    "            visit_weighted = True\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backup_mode: {self.backup_mode}\")\n",
    "\n",
    "        for i, (parent, action) in enumerate(reversed(search_path)):\n",
    "            child = parent.children[action]\n",
    "            child.visits += 1\n",
    "\n",
    "            if i == 0:\n",
    "                if not child.expanded():\n",
    "                    child.update(leaf_value, self.config.obs_var, self.config.min_variance)\n",
    "                else:\n",
    "                    if child.agg_mu is not None:\n",
    "                        child.mu = child.agg_mu\n",
    "                        child.sigma_sq = child.agg_sigma_sq\n",
    "\n",
    "            # Use configurable backup mode\n",
    "            parent.aggregate_children(\n",
    "                self.config.prune_threshold, \n",
    "                visited_only=visited_only,\n",
    "                visit_weighted=visit_weighted\n",
    "            )\n",
    "\n",
    "            if parent.agg_mu is not None:\n",
    "                parent.mu = parent.agg_mu\n",
    "                parent.sigma_sq = parent.agg_sigma_sq\n",
    "\n",
    "    def _get_policy(self, root: BayesianNodeVisitedOnly) -> np.ndarray:\n",
    "        policy = np.zeros(self.game.config.action_size, dtype=np.float32)\n",
    "\n",
    "        if not root.expanded():\n",
    "            return policy\n",
    "\n",
    "        actions = list(root.children.keys())\n",
    "        children = [root.children[a] for a in actions]\n",
    "        n = len(children)\n",
    "\n",
    "        if n == 1:\n",
    "            policy[actions[0]] = 1.0\n",
    "            return policy\n",
    "\n",
    "        mus = np.array([-c.mu for c in children])\n",
    "        sigma_sqs = np.array([c.sigma_sq for c in children])\n",
    "\n",
    "        sorted_idx = np.argsort(mus)[::-1]\n",
    "        leader_idx = sorted_idx[0]\n",
    "        challenger_idx = sorted_idx[1]\n",
    "\n",
    "        scores = np.zeros(n)\n",
    "        mu_L, sigma_sq_L = mus[leader_idx], sigma_sqs[leader_idx]\n",
    "        mu_C, sigma_sq_C = mus[challenger_idx], sigma_sqs[challenger_idx]\n",
    "\n",
    "        for i in range(n):\n",
    "            if i == leader_idx:\n",
    "                diff = mu_L - mu_C\n",
    "                std = math.sqrt(sigma_sq_L + sigma_sq_C)\n",
    "            else:\n",
    "                diff = mus[i] - mu_L\n",
    "                std = math.sqrt(sigma_sqs[i] + sigma_sq_L)\n",
    "\n",
    "            if std > 1e-10:\n",
    "                scores[i] = normal_cdf(diff / std)\n",
    "            else:\n",
    "                scores[i] = 1.0 if diff > 0 else 0.0\n",
    "\n",
    "        total = scores.sum()\n",
    "        if total < 1e-10:\n",
    "            for action in actions:\n",
    "                policy[action] = 1.0 / n\n",
    "        else:\n",
    "            for i, action in enumerate(actions):\n",
    "                policy[action] = scores[i] / total\n",
    "\n",
    "        return policy\n",
    "\n",
    "\n",
    "print(\"BayesianMCTSVisitedOnly class defined successfully.\")\n",
    "print(\"Backup modes: 'visited' (current), 'all' (include unvisited), 'weighted' (visit-weighted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Arena Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanozero.game import get_game\n",
    "from nanozero.model import AlphaZeroTransformer\n",
    "from nanozero.mcts import BatchedMCTS\n",
    "from nanozero.common import sample_action, load_checkpoint\n",
    "from nanozero.config import get_model_config, MCTSConfig, BayesianMCTSConfig\n",
    "\n",
    "\n",
    "def run_arena(game, model, puct_mcts, ttts_mcts, num_games, mcts_simulations):\n",
    "    \"\"\"\n",
    "    Run arena between PUCT and TTTS, return results from TTTS perspective.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (wins, draws, losses) for TTTS\n",
    "    \"\"\"\n",
    "    wins, draws, losses = 0, 0, 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        state = game.initial_state()\n",
    "        ttts_turn = 1 if i % 2 == 0 else -1  # Alternate who goes first\n",
    "\n",
    "        while not game.is_terminal(state):\n",
    "            current = game.current_player(state)\n",
    "            if current == ttts_turn:\n",
    "                policy = ttts_mcts.search(\n",
    "                    state[np.newaxis, ...], model,\n",
    "                    num_simulations=mcts_simulations\n",
    "                )[0]\n",
    "            else:\n",
    "                policy = puct_mcts.search(\n",
    "                    state[np.newaxis, ...], model,\n",
    "                    num_simulations=mcts_simulations, add_noise=False\n",
    "                )[0]\n",
    "            action = sample_action(policy, temperature=0)\n",
    "            state = game.next_state(state, action)\n",
    "\n",
    "        reward = game.terminal_reward(state)\n",
    "        final_player = game.current_player(state)\n",
    "\n",
    "        if final_player == ttts_turn:\n",
    "            ttts_result = reward\n",
    "        else:\n",
    "            ttts_result = -reward\n",
    "\n",
    "        if ttts_result > 0:\n",
    "            wins += 1\n",
    "        elif ttts_result < 0:\n",
    "            losses += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return wins, draws, losses\n",
    "\n",
    "\n",
    "print(\"Arena function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Ablation: Test Different backup_mode Settings\n",
    "\n",
    "Compare:\n",
    "- `visited`: Only aggregate visited children during backup (current)\n",
    "- `all`: Include all children's beliefs\n",
    "- `weighted`: Weight children by (visits + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "game = get_game('connect4', use_rust=True)\n",
    "print(f\"Game backend: {game.backend}\")\n",
    "\n",
    "model_config = get_model_config(game.config, n_layer=4)\n",
    "model = AlphaZeroTransformer(model_config).to(device)\n",
    "load_checkpoint('checkpoints/connect4_final.pt', model)\n",
    "model.eval()\n",
    "\n",
    "# Setup PUCT baseline\n",
    "puct_config = MCTSConfig()\n",
    "puct_mcts = BatchedMCTS(game, puct_config)\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation configuration\n",
    "backup_modes = ['visited', 'all', 'weighted']\n",
    "num_games = 100  # Per configuration\n",
    "mcts_simulations = 100\n",
    "seed = 42\n",
    "\n",
    "print(f\"\\nVisited-Only Ablation\")\n",
    "print(f\"=====================\")\n",
    "print(f\"Games per config: {num_games}\")\n",
    "print(f\"Simulations: {mcts_simulations}\")\n",
    "print(f\"Config: sigma_0=1.0, obs_var=1.0\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = []\n",
    "\n",
    "for mode in backup_modes:\n",
    "    # Create TTTS with this backup mode\n",
    "    ttts_config = BayesianMCTSConfig(\n",
    "        sigma_0=1.0,\n",
    "        obs_var=1.0,\n",
    "    )\n",
    "    ttts_mcts = BayesianMCTSVisitedOnly(game, ttts_config, backup_mode=mode)\n",
    "    \n",
    "    # Clear caches\n",
    "    puct_mcts.clear_cache()\n",
    "    ttts_mcts.clear_cache()\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Run arena\n",
    "    wins, draws, losses = run_arena(\n",
    "        game, model, puct_mcts, ttts_mcts,\n",
    "        num_games=num_games, mcts_simulations=mcts_simulations\n",
    "    )\n",
    "    \n",
    "    decisive = wins + losses\n",
    "    win_rate = wins / decisive if decisive > 0 else 0.5\n",
    "    \n",
    "    results.append({\n",
    "        'mode': mode,\n",
    "        'wins': wins,\n",
    "        'draws': draws,\n",
    "        'losses': losses,\n",
    "        'win_rate': win_rate,\n",
    "    })\n",
    "    \n",
    "    print(f\"{mode:12}: {wins}W/{draws}D/{losses}L  ({win_rate:.1%} decisive win rate)\")\n",
    "\n",
    "print(\"\\nAblation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "modes = [r['mode'] for r in results]\n",
    "win_rates = [r['win_rate'] for r in results]\n",
    "wins = [r['wins'] for r in results]\n",
    "draws = [r['draws'] for r in results]\n",
    "losses = [r['losses'] for r in results]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Win rate plot\n",
    "x = np.arange(len(modes))\n",
    "bars = ax1.bar(x, win_rates, color=['#2ecc71', '#3498db', '#9b59b6'], alpha=0.8)\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', label='50% baseline')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(modes)\n",
    "ax1.set_xlabel('Backup Mode', fontsize=12)\n",
    "ax1.set_ylabel('TTTS Win Rate vs PUCT', fontsize=12)\n",
    "ax1.set_title('Win Rate by Backup Mode', fontsize=14)\n",
    "ax1.set_ylim(0.3, 0.7)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Stacked bar chart\n",
    "width = 0.6\n",
    "\n",
    "ax2.bar(x, wins, width, label='Wins', color='green', alpha=0.8)\n",
    "ax2.bar(x, draws, width, bottom=wins, label='Draws', color='gray', alpha=0.8)\n",
    "ax2.bar(x, losses, width, bottom=[w+d for w, d in zip(wins, draws)], label='Losses', color='red', alpha=0.8)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(modes)\n",
    "ax2.set_xlabel('Backup Mode', fontsize=12)\n",
    "ax2.set_ylabel('Games', fontsize=12)\n",
    "ax2.set_title('Game Outcomes by Backup Mode', fontsize=14)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visited_only_ablation.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Find best mode\n",
    "best_idx = np.argmax(win_rates)\n",
    "best_mode = modes[best_idx]\n",
    "best_win_rate = win_rates[best_idx]\n",
    "\n",
    "print(f\"\\nBest backup mode: '{best_mode}' ({best_win_rate:.1%} win rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## Extended Ablation: Varying Simulation Counts\n",
    "\n",
    "Test if the optimal backup_mode changes with search depth.\n",
    "\n",
    "Hypothesis:\n",
    "- At low simulations (shallow search), `all` or `weighted` might help by leveraging NN priors\n",
    "- At high simulations (deep search), `visited` might be better since most children are visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended ablation with different sim counts\n",
    "backup_modes = ['visited', 'all', 'weighted']\n",
    "sim_counts = [25, 50, 100, 200]\n",
    "num_games = 60  # Fewer games per cell for faster testing\n",
    "\n",
    "print(f\"\\nExtended Ablation: Backup Mode x Simulation Count\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "extended_results = []\n",
    "\n",
    "for n_sims in sim_counts:\n",
    "    print(f\"\\n--- {n_sims} simulations ---\")\n",
    "    for mode in backup_modes:\n",
    "        ttts_config = BayesianMCTSConfig(\n",
    "            sigma_0=1.0,\n",
    "            obs_var=1.0,\n",
    "        )\n",
    "        ttts_mcts = BayesianMCTSVisitedOnly(game, ttts_config, backup_mode=mode)\n",
    "        \n",
    "        puct_mcts.clear_cache()\n",
    "        ttts_mcts.clear_cache()\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        wins, draws, losses = run_arena(\n",
    "            game, model, puct_mcts, ttts_mcts,\n",
    "            num_games=num_games, mcts_simulations=n_sims\n",
    "        )\n",
    "        \n",
    "        decisive = wins + losses\n",
    "        win_rate = wins / decisive if decisive > 0 else 0.5\n",
    "        \n",
    "        extended_results.append({\n",
    "            'n_sims': n_sims,\n",
    "            'mode': mode,\n",
    "            'wins': wins,\n",
    "            'draws': draws,\n",
    "            'losses': losses,\n",
    "            'win_rate': win_rate,\n",
    "        })\n",
    "        \n",
    "        print(f\"  {mode:12}: {wins}W/{draws}D/{losses}L ({win_rate:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize extended results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = {'visited': '#2ecc71', 'all': '#3498db', 'weighted': '#9b59b6'}\n",
    "\n",
    "for mode in backup_modes:\n",
    "    mode_results = [r for r in extended_results if r['mode'] == mode]\n",
    "    sims = [r['n_sims'] for r in mode_results]\n",
    "    rates = [r['win_rate'] for r in mode_results]\n",
    "    ax.plot(sims, rates, 'o-', linewidth=2, markersize=8, label=mode, color=colors[mode])\n",
    "\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', label='50% baseline')\n",
    "ax.set_xlabel('MCTS Simulations', fontsize=12)\n",
    "ax.set_ylabel('TTTS Win Rate vs PUCT', fontsize=12)\n",
    "ax.set_title('Backup Mode Effect Across Simulation Counts', fontsize=14)\n",
    "ax.set_ylim(0.3, 0.7)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visited_only_vs_sims.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis: Diagnostic Statistics\n",
    "\n",
    "Let's examine how many children are typically unvisited at different simulation counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: How many children are unvisited?\n",
    "def analyze_visit_distribution(game, model, ttts_mcts, num_games=20, n_sims=100):\n",
    "    \"\"\"Analyze visit distribution in TTTS search trees.\"\"\"\n",
    "    all_stats = []\n",
    "    \n",
    "    for _ in range(num_games):\n",
    "        state = game.initial_state()\n",
    "        ttts_mcts.clear_cache()\n",
    "        \n",
    "        # Just do one search\n",
    "        _ = ttts_mcts.search(state[np.newaxis, ...], model, num_simulations=n_sims)\n",
    "        \n",
    "        # Analyze root's children\n",
    "        if hasattr(ttts_mcts, '_last_roots'):  # Would need to add this\n",
    "            root = ttts_mcts._last_roots[0]\n",
    "        else:\n",
    "            # Re-run to get root\n",
    "            ttts_mcts.clear_cache()\n",
    "            non_terminal_states = np.array([state])\n",
    "            device = next(model.parameters()).device\n",
    "            roots, _ = ttts_mcts._batch_expand_roots(non_terminal_states, model, device)\n",
    "            \n",
    "            # Run simulations\n",
    "            for _ in range(n_sims):\n",
    "                leaf_node, search_path, leaf_state, is_terminal = ttts_mcts._select_to_leaf(roots[0], state)\n",
    "                if is_terminal:\n",
    "                    value = game.terminal_reward(leaf_state)\n",
    "                elif not leaf_node.expanded():\n",
    "                    values = ttts_mcts._batch_expand_leaves([leaf_node], [leaf_state], model, device)\n",
    "                    value = values[0]\n",
    "                else:\n",
    "                    value = leaf_node.mu\n",
    "                ttts_mcts._backup(search_path, value)\n",
    "            \n",
    "            root = roots[0]\n",
    "        \n",
    "        if root.expanded():\n",
    "            children = list(root.children.values())\n",
    "            visits = [c.visits for c in children]\n",
    "            n_children = len(children)\n",
    "            n_visited = sum(1 for v in visits if v > 0)\n",
    "            n_unvisited = n_children - n_visited\n",
    "            \n",
    "            all_stats.append({\n",
    "                'n_children': n_children,\n",
    "                'n_visited': n_visited,\n",
    "                'n_unvisited': n_unvisited,\n",
    "                'pct_unvisited': n_unvisited / n_children if n_children > 0 else 0,\n",
    "                'max_visits': max(visits) if visits else 0,\n",
    "                'min_visits': min(visits) if visits else 0,\n",
    "            })\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "\n",
    "# Run diagnostics at different simulation counts\n",
    "print(\"Visit Distribution Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for n_sims in [25, 50, 100, 200]:\n",
    "    ttts_config = BayesianMCTSConfig(sigma_0=1.0, obs_var=1.0)\n",
    "    ttts_mcts = BayesianMCTSVisitedOnly(game, ttts_config, backup_mode='visited')\n",
    "    \n",
    "    stats = analyze_visit_distribution(game, model, ttts_mcts, num_games=20, n_sims=n_sims)\n",
    "    \n",
    "    avg_children = np.mean([s['n_children'] for s in stats])\n",
    "    avg_unvisited = np.mean([s['n_unvisited'] for s in stats])\n",
    "    avg_pct_unvisited = np.mean([s['pct_unvisited'] for s in stats])\n",
    "    \n",
    "    print(f\"n_sims={n_sims:3d}: avg {avg_children:.1f} children, \"\n",
    "          f\"{avg_unvisited:.1f} unvisited ({avg_pct_unvisited:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Backup Mode Options\n",
    "\n",
    "| Mode | Description | When it might help |\n",
    "|------|-------------|--------------------|\n",
    "| `visited` | Only aggregate visited children | Default; avoids noise from unvisited priors |\n",
    "| `all` | Include all children's beliefs | Shallow search with informative NN priors |\n",
    "| `weighted` | Weight by (visits + 1) | Compromise; trusted moves weighted more |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **If `visited` is best**: Unvisited children's priors add noise; actual search results are more reliable\n",
    "2. **If `all` is best**: NN priors are informative enough that including them helps\n",
    "3. **If `weighted` is best**: Priors help but should be down-weighted vs visited children\n",
    "4. **If optimal varies with n_sims**: Consider adaptive strategy based on search depth\n",
    "\n",
    "### Next Steps Based on Results\n",
    "\n",
    "If a non-default mode performs better:\n",
    "1. Add `backup_mode` parameter to `BayesianMCTSConfig`\n",
    "2. Update `_backup()` method to use the configured mode\n",
    "3. Consider making it adaptive based on simulation count or tree depth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
